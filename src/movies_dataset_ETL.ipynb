{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💻ETL para Movies Dataset 🎥\n",
    "En el siguiente notebook se presentan las transformaciones requeridas para obtener un dataset limpio y confiable el cual va ser cargado a un modelo de recomendación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación librerias 📜\n",
    "\n",
    "Las librerias importadas son las necesarias para realizar con exito el proceso ETL, algunas librerias se eligen debido a las caracteristicas del dataset, por ejemplo el modulo **literal_eval** de la libreria **ast** se usa debido a que los datos de algunas columnas vienen como string pero en realidad representan una estructura de datos más compleja como un dict o un list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías requeridas.\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval # Importamos este modulo para convertir String a Dict y a List."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora leemos los datos desde un archivo CSV usando el metodo read_csv que provee pandas. En este paso hay que tener cuidado con la ruta donde se encuentra almacenado el archivos csv, para este caso accedemos de forma local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando la función read_csv de Pandas leemos y almacenamos movies_dataset como un dataframe con el nombre movies_data.\n",
    "movies_data = pd.read_csv('../datasets/movies_dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsualizamos las 5 primeras filas del dataframe así cómo las 5 últimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la ayuda del metodo head echamos un vistazo preeliminar al dataframe creado.\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la ayuda del metodo tail echamos un vistazo preeliminar al dataframe creado.\n",
    "movies_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desanidando 🪹\n",
    "\n",
    "Se procede a desanidar los campos de las columnas 'belongs_to_collection', 'genres', 'production_companies', 'production_countries' y 'spoken_languages'. El metodo usado es el resultado de varios pruebas realizadas con anterioridad para determinar cual es el mejor, inicialmente durante la exploración preeliminar se evidencia que los datos anidados vienen en tipo **str** y con el modulo **literal_eval** de la libreria **ast** se logra convertir a la forma ya sea **dict** o **list**, posteriormente se procede a desanidar y almacenar en dataframes independientes usando el modulo **json_normalize** de Pandas, este metodo se elige ya que se debe cumplir con rapidez con la tarea asignada y no vamos a reinventar la rueda, simplemente usamos lo que ya existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos un campo para cada columna que dice el diccionario de datos que están anidados para visualizar su estructura, luego imprimimos el typo de dato para evidenciar cómo viene formateado.\n",
    "print(movies_data['belongs_to_collection'][2])\n",
    "print(movies_data['genres'][2])\n",
    "print(movies_data['production_companies'][2])\n",
    "print(movies_data['production_countries'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data['belongs_to_collection'] = movies_data['belongs_to_collection'].apply(lambda x: literal_eval(x) if pd.notna(x) else float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data['belongs_to_collection'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data['belongs_to_collection'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
